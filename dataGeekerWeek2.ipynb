{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression implementation in tensorflow\n",
    "# data reference https://archive.ics.uci.edu/ml/datasets/Adult\n",
    "# task prediction task is to determine whether a person makes over 50K a year\n",
    "# data can download from https://ntumlta.github.io/2017fall-ml-hw2/\n",
    "# categorical variables:\n",
    "# workclass：(9包含未知项) Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked. \n",
    "# education:(16)[' 10th', ' 11th', ' 12th', ' 1st-4th', ' 5th-6th', ' 7th-8th',' 9th', ' Assoc-acdm', ' Assoc-voc', ' Bachelors', ' Doctorate',' HS-grad', ' Masters', ' Preschool', ' Prof-school',' Some-college']\n",
    "# marital_status:(7)[' Divorced', ' Married-AF-spouse', ' Married-civ-spouse',' Married-spouse-absent', ' Never-married', ' Separated',' Widowed']\n",
    "# occupation:(15包含未知项)[' ?', ' Adm-clerical', ' Armed-Forces', ' Craft-repair',' Exec-managerial', ' Farming-fishing', ' Handlers-cleaners',' Machine-op-inspct', ' Other-service', ' Priv-house-serv',' Prof-specialty', ' Protective-serv', ' Sales', ' Tech-support',' Transport-moving']\n",
    "# relationship:(6)[' Husband', ' Not-in-family', ' Other-relative', ' Own-child',' Unmarried', ' Wife']\n",
    "# race:(5)[' Amer-Indian-Eskimo', ' Asian-Pac-Islander', ' Black', ' Other', ' White']\n",
    "# sex:(2)\n",
    "# native_country:(42包含未知项)[' ?', ' Cambodia', ' Canada', ' China', ' Columbia', ' Cuba',' Dominican-Republic', ' Ecuador', ' El-Salvador', ' England',' France', ' Germany', ' Greece', ' Guatemala', ' Haiti',' Holand-Netherlands', ' Honduras', ' Hong', ' Hungary', ' India',' Iran', ' Ireland', ' Italy', ' Jamaica', ' Japan', ' Laos',' Mexico', ' Nicaragua', ' Outlying-US(Guam-USVI-etc)', ' Peru',' Philippines', ' Poland', ' Portugal', ' Puerto-Rico',' Scotland', ' South', ' Taiwan', ' Thailand', ' Trinadad&Tobago', ' United-States', ' Vietnam', ' Yugoslavia']\n",
    "# 1,3,5,6,7,8,13 #不对sex做one-hot-encoding\n",
    "# continuous:\n",
    "# age,fnlwgt,education_num,capital_gain,capital_loss,hours_per_week //education_num与education一一对应\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['age', 'workclass', 'fnlwgt', 'education', 'education_num',\n",
      "       'marital_status', 'occupation', 'relationship', 'race', 'sex',\n",
      "       'capital_gain', 'capital_loss', 'hours_per_week', 'native_country',\n",
      "       'income'],\n",
      "      dtype='object') (16281, 13)\n",
      "Index(['age', 'workclass', 'fnlwgt', 'education', 'education_num',\n",
      "       'marital_status', 'occupation', 'relationship', 'race', 'sex',\n",
      "       'capital_gain', 'capital_loss', 'hours_per_week', 'native_country'],\n",
      "      dtype='object') (16281, 14)\n",
      "(9,)\n",
      "(16,)\n",
      "(7,)\n",
      "(15,)\n",
      "(6,)\n",
      "(5,)\n",
      "(2,)\n",
      "(42,)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"./UCI/train.csv\")\n",
    "print(train.columns,test.shape)\n",
    "test = pd.read_csv(\"./UCI/test.csv\")\n",
    "print(test.columns,test.shape)\n",
    "\n",
    "X_train = train[train.columns[:14]]\n",
    "y_train = train[[\"income\"]]\n",
    "X_test = test\n",
    "print(np.unique(train.workclass).shape)\n",
    "print(np.unique(train.education).shape)\n",
    "print(np.unique(train.marital_status).shape)\n",
    "print(np.unique(train.occupation).shape)\n",
    "print(np.unique(train.relationship).shape)\n",
    "print(np.unique(train.race).shape)\n",
    "print(np.unique(train.sex).shape)\n",
    "print(np.unique(train.native_country).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = pd.read_csv(\"UCI/correct_answer.csv\")\n",
    "\n",
    "y_test = y_test[['label']].values\n",
    "\n",
    "y_test.shape\n",
    "\n",
    "# 对分类类别进行编码\n",
    "def labelEncoder(mapColumn,data):\n",
    "    mapping_digits = {label: idx for idx, label in enumerate(np.unique(data[mapColumn]))}\n",
    "    data[mapColumn] = data[mapColumn].map(mapping_digits)\n",
    "\n",
    "for columnName in [\"workclass\",\"education\",\"marital_status\",\"occupation\",\"relationship\",\"race\",\"sex\",\"native_country\"]:\n",
    "    labelEncoder(columnName,X_train)\n",
    "\n",
    "# 对y类类别进行分类处理：\n",
    "def labelEncoder1(mapColumn,data):\n",
    "    mapping_digits = {label: idx for idx, label in enumerate(np.unique(data[mapColumn]))}\n",
    "    data[mapColumn] = data[mapColumn].map(mapping_digits)\n",
    "    \n",
    "labelEncoder1(\"income\",y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>7</td>\n",
       "      <td>77516</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>83311</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>4</td>\n",
       "      <td>215646</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>4</td>\n",
       "      <td>234721</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>338409</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  workclass  fnlwgt  education  education_num  marital_status  \\\n",
       "0   39          7   77516          9             13               4   \n",
       "1   50          6   83311          9             13               2   \n",
       "2   38          4  215646         11              9               0   \n",
       "3   53          4  234721          1              7               2   \n",
       "4   28          4  338409          9             13               2   \n",
       "\n",
       "   occupation  relationship  race  sex  capital_gain  capital_loss  \\\n",
       "0           1             1     4    1          2174             0   \n",
       "1           4             0     4    1             0             0   \n",
       "2           6             1     4    1             0             0   \n",
       "3           6             0     2    1             0             0   \n",
       "4          10             5     2    0             0             0   \n",
       "\n",
       "   hours_per_week  native_country  \n",
       "0              40              39  \n",
       "1              13              39  \n",
       "2              40              39  \n",
       "3              40              39  \n",
       "4              40               5  "
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(categorical_features=np.array([False,True,False,True,False,True,True,True,True,False,False,False,False,True]))\n",
    "enc.fit(X_train)\n",
    "oneHot = enc.transform(X_train).toarray()\n",
    "oneHot[:,3]\n",
    "\n",
    "enc1 = OneHotEncoder(categorical_features = np.array([1,3,5,6,7,8,13]))\n",
    "enc1.fit(X_train)\n",
    "oneHotEncoding = enc1.transform(X_train).toarray()\n",
    "oneHotEncoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed = pd.read_csv(\"UCI/X_train\") # 在给的二进制文件当中，去掉了education_num这个变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lily/tf3.6/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "# transformed.education_num\n",
    "# X_train.education_num\n",
    "np.unique(X_train.education_num).shape\n",
    "X_train[['education_num','education']].groupby(['education_num','education']).count()\n",
    "educations = X_train[['education_num','education']].copy()\n",
    "educations['count'] = 1\n",
    "educations\n",
    "educations.pivot_table(values = 'count', index = ['education_num','education'],aggfunc = np.sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lily/tf3.6/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "#由上面分析可知 education与education_num是完全相关的，所以drop education_num这个变量\n",
    "\n",
    "X_train.drop(['education_num'],axis = 1, inplace=True)\n",
    "X_test.drop(['education_num'],axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "for columnName in [\"workclass\",\"education\",\"marital_status\",\"occupation\",\"relationship\",\"race\",\"sex\",\"native_country\"]:\n",
    "    labelEncoder(columnName,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 重新对上面的数据进行one_hot_encoding:\n",
    "enc = OneHotEncoder(categorical_features=np.array([False,True,False,True,True,True,True,True,False,False,False,False,True]))\n",
    "enc.fit(X_train)\n",
    "X_train_one_hot = enc.transform(X_train).toarray()\n",
    "X_test_one_hot = enc.transform(X_test).toarray()\n",
    "y_train = y_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _sigmoid(z):\n",
    "    res = 1/(1.0+bp.exp(-z))\n",
    "    return np.clip(res,1e-8,1-(1-(1e-8)))\n",
    "\n",
    "def _shuffle(X,y):\n",
    "    random_ind = np.arange(X.shape[0]) #或者是len(X)\n",
    "    np.random.shuffle(random_ind)\n",
    "    return (X[random_ind],y[random_ind])\n",
    "\n",
    "# 这里利用了train的数据的scale的参数对test数据做调整，将他们一起归一化会有data snooping的风险\n",
    "def _normalization(X_train, X_test):\n",
    "    n_samples = len(X_train)\n",
    "    mu = sum(X_train)/n_samples \n",
    "    sigma = np.std(X_train,axis=0)\n",
    "    mu_train = np.tile(mu,(n_samples ,1))\n",
    "    sigma_train = np.tile(sigma,(n_samples ,1))\n",
    "    mu_test = np.tile(mu,(len(X_test),1))\n",
    "    sigma_test = np.tile(sigma,(len(X_test),1))\n",
    "    X_train_normed = (X_train-mu_train)/sigma_train\n",
    "    \n",
    "    X_test_normed = (X_test-mu_test)/sigma_test\n",
    "    \n",
    "    return X_train_normed,X_test_normed\n",
    "\n",
    "def _train_valid_split(X,y,percentage):\n",
    "    n_samples = len(X)\n",
    "    train_samples = percentage*n_samples\n",
    "    \n",
    "    X,y = _shuffle(X,y)\n",
    "    \n",
    "    X_train,y_train = X[0:train_samples],y[0:train_samples]\n",
    "    X_valid,y_valid = X[train_samples:],y[train_samples:]\n",
    "    return X_train, y_train, X_valid, y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_one_hot_normed,X_test_one_hot_normed = _normalization(X_train_one_hot, X_test_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost= 0.458120400\n",
      "Epoch: 0002 cost= 0.362409745\n",
      "Epoch: 0003 cost= 0.343075651\n",
      "Epoch: 0004 cost= 0.335331411\n",
      "Epoch: 0005 cost= 0.330849974\n",
      "Epoch: 0006 cost= 0.327954126\n",
      "Epoch: 0007 cost= 0.326058585\n",
      "Epoch: 0008 cost= 0.324586529\n",
      "Epoch: 0009 cost= 0.323434817\n",
      "Epoch: 0010 cost= 0.322656993\n",
      "Epoch: 0011 cost= 0.321798680\n",
      "Epoch: 0012 cost= 0.321398948\n",
      "Epoch: 0013 cost= 0.320848041\n",
      "Epoch: 0014 cost= 0.320367563\n",
      "Epoch: 0015 cost= 0.320022907\n",
      "Epoch: 0016 cost= 0.319778411\n",
      "Epoch: 0017 cost= 0.319437499\n",
      "Epoch: 0018 cost= 0.319150175\n",
      "Epoch: 0019 cost= 0.318942014\n",
      "Epoch: 0020 cost= 0.318721447\n",
      "Epoch: 0021 cost= 0.318568437\n",
      "Epoch: 0022 cost= 0.318395416\n",
      "Epoch: 0023 cost= 0.318230023\n",
      "Epoch: 0024 cost= 0.318177779\n",
      "Epoch: 0025 cost= 0.318039424\n",
      "Epoch: 0026 cost= 0.318062882\n",
      "Epoch: 0027 cost= 0.317906852\n",
      "Epoch: 0028 cost= 0.317667780\n",
      "Epoch: 0029 cost= 0.317556435\n",
      "Epoch: 0030 cost= 0.317528576\n",
      "Epoch: 0031 cost= 0.317418609\n",
      "Epoch: 0032 cost= 0.317630326\n",
      "Epoch: 0033 cost= 0.317390102\n",
      "Epoch: 0034 cost= 0.317384628\n",
      "Epoch: 0035 cost= 0.317342709\n",
      "Epoch: 0036 cost= 0.317327493\n",
      "Epoch: 0037 cost= 0.317263481\n",
      "Epoch: 0038 cost= 0.317173356\n",
      "Epoch: 0039 cost= 0.317258489\n",
      "Epoch: 0040 cost= 0.317136216\n",
      "Optimization Finished\n",
      "Train Accuracy 0.85347503\n",
      "Test Accuracy 0.84208584\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4a6cc9cda0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tensorflow Implementation\n",
    "# tf.Graph 输入\n",
    "# 给输入的分区不指定样本的数量，便于调整batch normalization的值\n",
    "# 输入的数据是float类型\n",
    "n_samples = len(X_train_one_hot_normed)\n",
    "n_features = X_train_one_hot_normed.shape[1]\n",
    "x = tf.placeholder(tf.float32 ,[None, n_features])\n",
    "y = tf.placeholder(tf.float32 ,[None, 1]) #在这里因为是二分类问题就没有定义多个输出\n",
    "\n",
    "# 模型待估计参数\n",
    "W = tf.Variable(tf.zeros([n_features,1]))\n",
    "b = tf.Variable(tf.zeros([1]))\n",
    "\n",
    "## hyperparameter\n",
    "learning_rate = 0.02\n",
    "train_epochs = 40\n",
    "batch_size = 100\n",
    "display_step = 1\n",
    "\n",
    "# 定义模型的输出\n",
    "pred = tf.matmul(x, W) + b\n",
    "\n",
    "# 定义模型的损失函数：逻辑回归采用交叉熵\n",
    "cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = pred,labels = y))\n",
    "# 这里的损失函数不能够直接按照第二个自己定义的，可能原因是log(1+x),当x很小的时候可能返回的参数是零，\n",
    "# 在tensorflow的实现当中使用了log1p(),这个函数在numpy中的精度比直接计算log(1+x)要高（可能原因）\n",
    "cost1 = tf.reduce_mean(-y*tf.log(tf.nn.sigmoid(pred))-(1-y)*tf.log(1-tf.nn.sigmoid(pred)))\n",
    "\n",
    "# 梯度下降\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "# 初始化参数\n",
    "# 注意在计算开始之前必须初始化参数，而且注意当参数初始化有执行顺序的时候，需要自己的定义初始化过程\n",
    "# init = tf.global_varibales_initializer()(这个方法已经被废弃的)\n",
    "# init = tf.initializers.global_variables()\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "# 定义模型的准确性\n",
    "# 如果说输出是多个节点，那么用tf.argmax(input, axis=None)，这里采用tf.argmax(input,axis=1)\n",
    "predLabel = tf.round(tf.sigmoid(pred))\n",
    "correct = tf.equal(predLabel, y)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, dtype=tf.float32))\n",
    "\n",
    "# 模型训练\n",
    "# 注意会话窗口的正常关闭，如果不采用以下上下文结构的化，否则程序会有溢出的报错\n",
    "# 在tensorflow的结构下面，如果会话没有执行，基本上所有的函数返回的都只是操作，必须在会话中执行之后才会有返回值\n",
    "with tf.Session() as sess:\n",
    "    # 初始化参数\n",
    "    sess.run(init)\n",
    "    \n",
    "    # 按照epoch训练，一个epoch就遍历所有的训练集\n",
    "    for epoch in range(train_epochs):\n",
    "        X_train_one_hot_normed, y_train = _shuffle(X_train_one_hot_normed,y_train)\n",
    "        avg_cost = 0\n",
    "        if n_samples % batch_size == 0:\n",
    "            batches = n_samples//batch_size\n",
    "        else:\n",
    "            batches = n_samples//batch_size+1\n",
    "        for i in range(batches):\n",
    "            # sess.run()对应返回的是fetches的参数\n",
    "            if (i+1)*batch_size <= n_samples:\n",
    "                _, cos,cos1 = sess.run([optimizer, cost,cost1], \n",
    "                                  feed_dict ={x:X_train_one_hot_normed[i*batch_size:(i+1)*batch_size],\n",
    "                                             y:y_train[i*batch_size:(i+1)*batch_size]})\n",
    "            else:\n",
    "                _, cos,cos1 = sess.run([optimizer, cost,cost1], \n",
    "                                  feed_dict ={x:X_train_one_hot_normed[i*batch_size:],\n",
    "                                             y:y_train[i*batch_size:]})\n",
    "            # 计算损失函数\n",
    "            # print(cos,cos1) cos1经常无法计算\n",
    "            avg_cost += cos/batches\n",
    "        \n",
    "        plt.plot(epoch+1, avg_cost, 'co')\n",
    "        \n",
    "        #每display_step时间显示日志\n",
    "        if (epoch+1)%display_step == 0:\n",
    "            print(\"Epoch:\", \"%04d\"%(epoch+1), \"cost=\",\"{:.9f}\".format(avg_cost))\n",
    "            \n",
    "    print(\"Optimization Finished\")\n",
    "    \n",
    "    # 测试模型\n",
    "    # eval()也是启动计算的一种方式，与session.run()有同样的作用，也就是说输入的是字典里面的参数，返回accuracy\n",
    "    # accuracy.eval({})就是 sess.run(accuracy, feed_dict = {})\n",
    "    print(\"Train Accuracy\", accuracy.eval({x:X_train_one_hot_normed,y:y_train}))\n",
    "    print(\"Test Accuracy\", accuracy.eval({x:X_test_one_hot_normed,y:y_test}))\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Cost\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[1:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
